{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO55JFFlvnAfuvT+foNcmX4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Redcoder815/Machine_Learning/blob/main/LossFunction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Mean squared error\n"
      ],
      "metadata": {
        "id": "O0rQD4IJMrKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleLinearRegression:\n",
        "    def __init__(self):\n",
        "        self.slope = 0\n",
        "        self.intercept = 0\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.intercept + self.slope * X\n",
        "\n",
        "    def get_mse(self, X, y_actual):\n",
        "        y_pred = self.predict(X)\n",
        "        return np.mean((y_actual - y_pred)**2)\n",
        "\n",
        "# Calculation steps summary:\n",
        "# 1. Residuals: (y_actual - y_pred)\n",
        "# 2. Square: (error)^2\n",
        "# 3. Sum: Total squared error\n",
        "# 4. Average: Sum / number of observations\n",
        "# or different way\n",
        "import numpy as np\n",
        "\n",
        "def numpy_mse(actual, predicted):\n",
        "    actual, predicted = np.array(actual), np.array(predicted)\n",
        "    # The vectorized approach: subtract, square, then mean\n",
        "    return np.mean((actual - predicted)**2)\n",
        "\n",
        "\n",
        "y_true = [3.4, 5.8, 7.2, 9.8]\n",
        "y_pred = [2.1, 4.8, 6.1, 9.3]\n",
        "\n",
        "# Usage\n",
        "mse_value = numpy_mse(y_true, y_pred)\n"
      ],
      "metadata": {
        "id": "wdBi2TeKM0-Y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean absolute errror\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QyediGcpRAJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_mae(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Computes the Mean Absolute Error from scratch.\n",
        "    \"\"\"\n",
        "    n = len(y_true)\n",
        "    absolute_errors = np.abs(y_true - y_pred)\n",
        "    mae = np.sum(absolute_errors) / n\n",
        "    return mae\n"
      ],
      "metadata": {
        "id": "cBMuMjVoRD0L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Root mean squared error"
      ],
      "metadata": {
        "id": "JbfoB9dMRnpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_rmse(y_actual, y_predicted):\n",
        "    \"\"\"\n",
        "    Calculates Root Mean Squared Error.\n",
        "    y_actual: array of ground truth values\n",
        "    y_predicted: array of values predicted by the linear model\n",
        "    \"\"\"\n",
        "    # 1. Calculate the difference (residuals)\n",
        "    errors = y_actual - y_predicted\n",
        "\n",
        "    # 2. Square the errors\n",
        "    squared_errors = errors ** 2\n",
        "\n",
        "    # 3. Calculate the Mean of the squared errors\n",
        "    mean_squared_error = np.mean(squared_errors)\n",
        "\n",
        "    # 4. Take the square root\n",
        "    rmse = np.sqrt(mean_squared_error)\n",
        "\n",
        "    return rmse\n",
        "\n",
        "# Example Usage:\n",
        "y_true = np.array([3.0, -0.5, 2.0, 7.0])\n",
        "y_pred = np.array([2.5, 0.0, 2.1, 7.8])\n",
        "\n",
        "print(f\"RMSE: {calculate_rmse(y_true, y_pred)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upY44p3XRquS",
        "outputId": "05e509fb-a981-4edd-888f-f8bf72e2b6db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.5361902647381803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Relative squared error"
      ],
      "metadata": {
        "id": "_YgFkPqiSTzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_rse(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculates Relative Squared Error (RSE).\n",
        "    \"\"\"\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # Sum of Squared Errors (Residuals)\n",
        "    sse = np.sum((y_true - y_pred)**2)\n",
        "\n",
        "    # Total Sum of Squares (relative to the mean)\n",
        "    y_mean = np.mean(y_true)\n",
        "    tss = np.sum((y_true - y_mean)**2)\n",
        "\n",
        "    # Calculate RSE\n",
        "    rse = sse / tss\n",
        "    return rse\n",
        "\n",
        "# Example Usage\n",
        "y_actual = [10, 20, 30, 40, 50]\n",
        "y_predicted = [12, 18, 33, 45, 48]\n",
        "\n",
        "print(f\"Relative Squared Error: {calculate_rse(y_actual, y_predicted):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeKU1UC0SZFA",
        "outputId": "bd9b865f-3765-47ce-b0e7-17b5a9c2f7f8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relative Squared Error: 0.0460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cohen's kappa loss"
      ],
      "metadata": {
        "id": "fbLQPRu3T5lo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def cohen_kappa_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculates Cohen's Kappa. Since Decision Trees maximize\n",
        "    gain, we use the raw Kappa value as the 'score'.\n",
        "    \"\"\"\n",
        "    classes = np.unique(y_true)\n",
        "    n = len(y_true)\n",
        "    if n == 0: return 0\n",
        "\n",
        "    # Observed agreement (Accuracy)\n",
        "    po = np.sum(y_true == y_pred) / n\n",
        "\n",
        "    # Expected agreement (Random chance)\n",
        "    pe = 0\n",
        "    for cls in classes:\n",
        "        p_true = np.sum(y_true == cls) / n\n",
        "        p_pred = np.sum(y_pred == cls) / n\n",
        "        pe += (p_true * p_pred)\n",
        "\n",
        "    if pe == 1: return 1 # Avoid division by zero\n",
        "    return (po - pe) / (1 - pe)\n"
      ],
      "metadata": {
        "id": "-xsFZ03vT9K5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross entrophy loss"
      ],
      "metadata": {
        "id": "G0p5umXnVGXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def compute_loss(self, y, y_pred):\n",
        "        # Adding a small epsilon to prevent log(0) errors\n",
        "        epsilon = 1e-15\n",
        "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
        "        return -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n"
      ],
      "metadata": {
        "id": "FiJEHH-dVLw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Binary cross entrophy loss"
      ],
      "metadata": {
        "id": "8SsLtOTMVq9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def _compute_loss(self, y, y_pred):\n",
        "        # Add epsilon to avoid log(0) errors\n",
        "        epsilon = 1e-15\n",
        "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
        "        return -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n"
      ],
      "metadata": {
        "id": "VY_vSzTzVx7b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}